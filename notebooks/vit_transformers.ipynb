{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful settings for interactive work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import sousvide.synthesize.rollout_generator as rg\n",
    "import sousvide.synthesize.observation_generator as og\n",
    "import sousvide.instruct.train_policy as tp\n",
    "import sousvide.visualize.plot_synthesize as ps\n",
    "import sousvide.visualize.plot_learning as pl\n",
    "import sousvide.flight.deploy_figs as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"transformers\"             # cohort name\n",
    "\n",
    "data_method = \"eval_single\"          # method name\n",
    "\n",
    "scene = \"mid_gate\"                  # scene name\n",
    "\n",
    "courses = [                         # course names\n",
    "    \"hover\",\n",
    "    ]   \n",
    "\n",
    "roster = [\n",
    "    \"hsDavion\",                     # sifu_testbed\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Rollouts\n",
    "rg.generate_rollout_data(cohort,courses,scene,data_method)\n",
    "\n",
    "# Review the Rollout Data\n",
    "ps.plot_rollout_data(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import torch\n",
    "import figs.visualize.generate_videos as gv\n",
    "\n",
    "K = np.array([\n",
    "    [ 462.956,   0.000, 323.076],\n",
    "    [   0.000, 463.002, 181.184],\n",
    "    [   0.000,   0.000,   1.000]\n",
    "])\n",
    "Tc2i = np.array([\n",
    "    [ 0.00000,  0.00000, -1.00000,  0.10000],\n",
    "    [ 1.00000,  0.00000,  0.00000, -0.03000],\n",
    "    [ 0.00000, -1.00000,  0.00000, -0.01000],\n",
    "    [ 0.00000,  0.00000,  0.00000,  1.00000]\n",
    "])\n",
    "Ti2c = np.linalg.inv(Tc2i)\n",
    "Rgl2cv = np.array([\n",
    "    [ 1.0, 0.0, 0.0],\n",
    "    [ 0.0,-1.0, 0.0],\n",
    "    [ 0.0, 0.0,-1.0]\n",
    "])\n",
    "\n",
    "def pose2proj(xcr,xds):\n",
    "    # Goal Frame to World Frame\n",
    "    Tds2wd = np.eye(4)\n",
    "    Tds2wd[0:3,0:3] = R.from_quat(xds[6:10]).as_matrix()\n",
    "    Tds2wd[0:3,3] = xds[0:3]\n",
    "\n",
    "    # World Frame to Current Frame\n",
    "    Twd2cr = np.eye(4)\n",
    "    Twd2cr[0:3,0:3] = R.from_quat(xcr[6:10]).as_matrix().T\n",
    "    Twd2cr[0:3,3] = -Twd2cr[0:3,0:3]@xcr[0:3]\n",
    "\n",
    "    # Position in camera frame\n",
    "    rc = Ti2c@Twd2cr@Tds2wd@rg\n",
    "    rc = rc[0:3,:]\n",
    "    # Switch to OpenCV convention\n",
    "    rc = Rgl2cv@rc\n",
    "    # Project to Image Plane\n",
    "    r_pr = K@rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trajectories\n",
    "course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"robustness_track\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"hover\")\n",
    "\n",
    "Trajectories = torch.load(os.path.join(course_directory,\"trajectories\",\"trajectories000.pt\"))\n",
    "Images = torch.load(os.path.join(course_directory,\"images\",\"images000.pt\"))\n",
    "\n",
    "trajectories = Trajectories[0]\n",
    "images = Images[0]\n",
    "\n",
    "Tro,Xro,tXd = trajectories[\"Tro\"],trajectories[\"Xro\"],trajectories[\"tXd\"]\n",
    "\n",
    "\n",
    "Iro = 1*images[\"images\"]\n",
    "Nro = len(Tro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst,nst = 10,4\n",
    "Nst = dst*nst\n",
    "for i in range(Nro):\n",
    "    idx_rf = np.arange(i+dst,i+Nst+1,dst)\n",
    "    idx_rf = np.clip(idx_rf,0,Nro-1)\n",
    "    Xrf = Xro[:,idx_rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft,nb = 20,2\n",
    "Nres,Nro = 100,\n",
    "\n",
    "# Extract future poses\n",
    "ob = np.zeros((4,1))\n",
    "xb = np.zeros((4,Nres))\n",
    "yb = np.zeros((4,Nres))\n",
    "zb = np.zeros((4,Nres))\n",
    "xb[0,:] = np.linspace(0.0,0.3,Nres)\n",
    "yb[1,:] = np.linspace(0.0,0.3,Nres)\n",
    "zb[2,:] = np.linspace(0.0,0.1,Nres)\n",
    "xb[3,:],yb[3,:],zb[3,:] = 1.0,1.0,1.0\n",
    "\n",
    "rinit = [xb,yb,zb]\n",
    "for i in range(Nro):\n",
    "    # Get index\n",
    "    g = np.min([i+nft,len(Tro)-1])\n",
    "\n",
    "    # Goal Frame to World Frame\n",
    "    Tg2w = np.eye(4)\n",
    "    Tg2w[0:3,0:3] = R.from_quat(Xro[6:10,g]).as_matrix()\n",
    "    Tg2w[0:3,3] = Xro[0:3,g]\n",
    "\n",
    "    # World Frame to Current Frame\n",
    "    Tw2i = np.eye(4)\n",
    "    Tw2i[0:3,0:3] = R.from_quat(Xro[6:10,i]).as_matrix().T\n",
    "    Tw2i[0:3,3] = -Tw2i[0:3,0:3]@Xro[0:3,i]\n",
    "\n",
    "    refs = []\n",
    "    for idx,rg in enumerate(rinit):\n",
    "        # Position in camera frame\n",
    "        rc = Ti2c@Tw2i@Tg2w@rg\n",
    "        rc = rc[0:3,:]\n",
    "\n",
    "        # Switch to OpenCV convention\n",
    "        rc = Rgl2cv@rc\n",
    "\n",
    "        # Project to Image Plane\n",
    "        r_pr = K@rc\n",
    "        # Append to list\n",
    "        refs.append(r_pr)\n",
    "\n",
    "    # Handle Reference Arrows\n",
    "    for j in range(Nres):\n",
    "        for k in range(3):\n",
    "            z = refs[k][2,j]\n",
    "            width  = int(refs[k][0,j]/z)\n",
    "            height = int(refs[k][1,j]/z)\n",
    "\n",
    "            if z > 0 and width > 0 and width < 640 and height > 0 and height < 360:\n",
    "                Iro[i,height-nb:height+nb,width-nb:width+nb,:] = 0\n",
    "                Iro[i,height-nb:height+nb,width-nb:width+nb,k] = 255\n",
    "\n",
    "gv.images_to_mp4(Iro,'output.mp4', 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitchen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
