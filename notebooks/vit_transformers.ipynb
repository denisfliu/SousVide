{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful settings for interactive work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/envs/kitchen/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.1'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Import the relevant modules\n",
    "import sousvide.synthesize.rollout_generator as rg\n",
    "import sousvide.synthesize.observation_generator as og\n",
    "import sousvide.instruct.train_policy as tp\n",
    "import sousvide.visualize.plot_synthesize as ps\n",
    "import sousvide.visualize.plot_learning as pl\n",
    "import sousvide.flight.deploy_figs as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"forces\"             # cohort name\n",
    "\n",
    "data_methods = [\n",
    "    # \"data_beta_f0\",                  # method name\n",
    "    # \"data_beta_f1\",\n",
    "    # \"data_beta_f2\",\n",
    "    # \"data_beta_f3\",\n",
    "    # \"data_beta_f4\",\n",
    "    # \"data_beta_f5\",\n",
    "    \"eval_single_f5\"\n",
    "]\n",
    "\n",
    "scene = \"mid_gate\"                  # scene name\n",
    "\n",
    "courses = [                         # course names\n",
    "    # \"hover\",\n",
    "    \"line\",\n",
    "    # \"robustness_track\"\n",
    "    ]   \n",
    "\n",
    "roster = [\n",
    "    \"Maverick\",                     # sifu_testbed\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Rollouts\n",
    "for data_method in data_methods:\n",
    "    rg.generate_rollout_data(cohort,courses,scene,data_method,\n",
    "                             expert_name=\"vrmpc_fe\")\n",
    "    \n",
    "# Review the Rollout Data\n",
    "ps.plot_rollout_data(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import torch\n",
    "import figs.visualize.generate_videos as gv\n",
    "\n",
    "K = np.array([\n",
    "    [ 462.956,   0.000, 323.076],\n",
    "    [   0.000, 463.002, 181.184],\n",
    "    [   0.000,   0.000,   1.000]\n",
    "])\n",
    "Tcm2cr = np.array([\n",
    "    [ 0.00000,  0.00000, -1.00000,  0.10000],\n",
    "    [ 1.00000,  0.00000,  0.00000, -0.03000],\n",
    "    [ 0.00000, -1.00000,  0.00000, -0.01000],\n",
    "    [ 0.00000,  0.00000,  0.00000,  1.00000]\n",
    "])\n",
    "Tcr2cm = np.linalg.inv(Tcm2cr)\n",
    "Rgl2cv = np.array([\n",
    "    [ 1.0, 0.0, 0.0],\n",
    "    [ 0.0,-1.0, 0.0],\n",
    "    [ 0.0, 0.0,-1.0]\n",
    "])\n",
    "\n",
    "def pose2proj(xcr,Xds,nb=20):\n",
    "    # Goal Frame to World Frame\n",
    "    Pds = Xds[0:3,:]\n",
    "    Pds = np.vstack((Pds,np.ones((1,Pds.shape[1]))))\n",
    "\n",
    "    # World Frame to Current Frame\n",
    "    Twd2cr = np.eye(4)\n",
    "    Twd2cr[0:3,0:3] = R.from_quat(xcr[6:10]).as_matrix().T\n",
    "    Twd2cr[0:3,3] = -Twd2cr[0:3,0:3]@xcr[0:3]\n",
    "\n",
    "    # Positions in camera frame\n",
    "    Pcm = Tcr2cm@Twd2cr@Pds\n",
    "    Pcm = Pcm[0:3,:]\n",
    "\n",
    "    # Switch to OpenCV convention\n",
    "    Pcm = Rgl2cv@Pcm\n",
    "\n",
    "    # Project to Image Plane\n",
    "    Ppr = K@Pcm\n",
    "\n",
    "    # Normalize by z\n",
    "    width  = Ppr[0,:]/(Ppr[2,:])\n",
    "    height = Ppr[1,:]/(Ppr[2,:])\n",
    "\n",
    "    # Clip to image size\n",
    "    width = np.clip(width,0+nb,640-nb)\n",
    "    height = np.clip(height,0+nb,360-nb)\n",
    "\n",
    "    # Package\n",
    "    UV = np.vstack((width,height))\n",
    "    UV = UV.astype(int)\n",
    "    \n",
    "    return UV\n",
    "\n",
    "def pose2line(xcr,xds):\n",
    "    Nl = 10\n",
    "    Lds_cr = np.zeros((3,Nl))\n",
    "    Lds_cr[1,:] = np.linspace(-0.1,0.1,Nl)\n",
    "\n",
    "    tds_wd = xds[0:3]\n",
    "    Rds2wd = R.from_quat(xds[6:10]).as_matrix()\n",
    "\n",
    "    Lds_wd = Rds2wd@Lds_cr + tds_wd[:,np.newaxis]\n",
    "\n",
    "    Width,Height = pose2proj(xcr,Lds_wd)\n",
    "\n",
    "    return Width,Height\n",
    "\n",
    "def pose2edges(xcr,xds,z_gain=1.0):\n",
    "    Lds_cr = np.array([\n",
    "        [ 0.0, 0.0],\n",
    "        [-0.1, 0.1],\n",
    "        [ 0.0, 0.0]\n",
    "    ])\n",
    "\n",
    "    tds_wd = xds[0:3]\n",
    "    Rds2wd = R.from_quat(xds[6:10]).as_matrix()\n",
    "\n",
    "    Lds_wd = Rds2wd@Lds_cr + tds_wd[:,np.newaxis]\n",
    "\n",
    "    UV = pose2proj(xcr,Lds_wd,z_gain)\n",
    "\n",
    "    return UV\n",
    "\n",
    "def get_patch_index(u,v, patch_height, patch_width, n_rows, n_cols):\n",
    "\n",
    "    row = int(v / patch_height)\n",
    "    col = int(u / patch_width)\n",
    "\n",
    "    # Clamp to valid index range\n",
    "    row = min(max(row, 0), n_rows - 1)\n",
    "    col = min(max(col, 0), n_cols - 1)\n",
    "\n",
    "    return row, col\n",
    "\n",
    "def get_patch_bounds(u,v, H, W, n_rows, n_cols):\n",
    "    patch_height = H / n_rows\n",
    "    patch_width = W / n_cols\n",
    "\n",
    "    row,col = get_patch_index(u,v, patch_height, patch_width, n_rows, n_cols)\n",
    "\n",
    "    top = int(round(row * patch_height))\n",
    "    bottom = int(round((row + 1) * patch_height))\n",
    "    left = int(round(col * patch_width))\n",
    "    right = int(round((col + 1) * patch_width))\n",
    "\n",
    "    return [top, bottom, left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trajectories\n",
    "course_directory = os.path.join(\"..\",\"cohorts\",\"transformers\",\"rollout_data\",\"robustness_track\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single_f1\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single_f2\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single_f3\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single_f4\")\n",
    "# course_directory = os.path.join(\"..\",\"cohorts\",cohort,\"rollout_data\",\"line_eval_single_f5\")\n",
    "\n",
    "Trajectories = torch.load(os.path.join(course_directory,\"trajectories\",\"trajectories000.pt\"))\n",
    "Images = torch.load(os.path.join(course_directory,\"images\",\"images000.pt\"))\n",
    "\n",
    "trajectories = Trajectories[0]\n",
    "images = Images[0]\n",
    "\n",
    "Tro,Xro,tXd = trajectories[\"Tro\"],trajectories[\"Xro\"],trajectories[\"tXd\"]\n",
    "\n",
    "Nro = len(Tro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iro = 1*images[\"images\"]\n",
    "\n",
    "height,width = Iro.shape[1],Iro.shape[2]\n",
    "n_rows,n_cols = 64,64\n",
    "\n",
    "nb = 5\n",
    "dini,dst,nst = 10,5,10\n",
    "Nst = dst*nst\n",
    "clr = int(255/nst)\n",
    "for i in range(Nro-1):\n",
    "    idx_rf = np.arange(i+dini+dst,i+Nst+dini+1,dst)\n",
    "    idx_rf = np.clip(idx_rf,0,Nro-1)\n",
    "    Xrf = Xro[:,idx_rf]\n",
    "\n",
    "    UV = []\n",
    "    for j in range(nst):\n",
    "        UV.append(pose2edges(Xro[:,i], Xrf[:,j]))\n",
    "    UV = np.hstack(UV)\n",
    "\n",
    "    for j in range(UV.shape[1]):\n",
    "        idx = j//2\n",
    "        u,v = UV[0,j],UV[1,j]\n",
    "        bnds = get_patch_bounds(u,v,height,width,n_rows,n_cols)\n",
    "\n",
    "        Iro[i,bnds[0]:bnds[1],bnds[2]:bnds[3],:] = 0\n",
    "        Iro[i,bnds[0]:bnds[1],bnds[2]:bnds[3],1] = 255\n",
    "        Iro[i,bnds[0]:bnds[1],bnds[2]:bnds[3],2] = idx*clr\n",
    "#     for k in range(Width.shape[0]):\n",
    "#         width = np.clip(Width[k],1,639)\n",
    "#         height = np.clip(Height[k],1,359)\n",
    "\n",
    "#         Iro[i,height-nb:height+nb,width-nb:width+nb,:] = 0\n",
    "#         Iro[i,height-nb:height+nb,width-nb:width+nb,1] = 255\n",
    "\n",
    "gv.images_to_mp4(Iro,'output.mp4', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft,nb = 20,2\n",
    "Nres,Nro = 100,\n",
    "\n",
    "# Extract future poses\n",
    "ob = np.zeros((4,1))\n",
    "xb = np.zeros((4,Nres))\n",
    "yb = np.zeros((4,Nres))\n",
    "zb = np.zeros((4,Nres))\n",
    "xb[0,:] = np.linspace(0.0,0.3,Nres)\n",
    "yb[1,:] = np.linspace(0.0,0.3,Nres)\n",
    "zb[2,:] = np.linspace(0.0,0.1,Nres)\n",
    "xb[3,:],yb[3,:],zb[3,:] = 1.0,1.0,1.0\n",
    "\n",
    "rinit = [xb,yb,zb]\n",
    "for i in range(Nro):\n",
    "    # Get index\n",
    "    g = np.min([i+nft,len(Tro)-1])\n",
    "\n",
    "    # Goal Frame to World Frame\n",
    "    Tg2w = np.eye(4)\n",
    "    Tg2w[0:3,0:3] = R.from_quat(Xro[6:10,g]).as_matrix()\n",
    "    Tg2w[0:3,3] = Xro[0:3,g]\n",
    "\n",
    "    # World Frame to Current Frame\n",
    "    Tw2i = np.eye(4)\n",
    "    Tw2i[0:3,0:3] = R.from_quat(Xro[6:10,i]).as_matrix().T\n",
    "    Tw2i[0:3,3] = -Tw2i[0:3,0:3]@Xro[0:3,i]\n",
    "\n",
    "    refs = []\n",
    "    for idx,rg in enumerate(rinit):\n",
    "        # Position in camera frame\n",
    "        rc = Ti2c@Tw2i@Tg2w@rg\n",
    "        rc = rc[0:3,:]\n",
    "\n",
    "        # Switch to OpenCV convention\n",
    "        rc = Rgl2cv@rc\n",
    "\n",
    "        # Project to Image Plane\n",
    "        r_pr = K@rc\n",
    "        # Append to list\n",
    "        refs.append(r_pr)\n",
    "\n",
    "    # Handle Reference Arrows\n",
    "    for j in range(Nres):\n",
    "        for k in range(3):\n",
    "            z = refs[k][2,j]\n",
    "            width  = int(refs[k][0,j]/z)\n",
    "            height = int(refs[k][1,j]/z)\n",
    "\n",
    "            if z > 0 and width > 0 and width < 640 and height > 0 and height < 360:\n",
    "                Iro[i,height-nb:height+nb,width-nb:width+nb,:] = 0\n",
    "                Iro[i,height-nb:height+nb,width-nb:width+nb,k] = 255\n",
    "\n",
    "gv.images_to_mp4(Iro,'output.mp4', 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitchen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
