{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful settings for interactive work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/envs/kitchen/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Import the relevant modules\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sousvide.synthesize.rollout_generator as rg\n",
    "import sousvide.synthesize.observation_generator as og\n",
    "import sousvide.control.networks.feature_extractors as fe\n",
    "import sousvide.utilities.feature_utilities as fu\n",
    "import figs.visualize.generate_videos as gv\n",
    "import figs.utilities.transform_helper as th\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"features\"\n",
    "\n",
    "data_method = \"eval_single\"\n",
    "eval_method = \"eval_single\"\n",
    "\n",
    "scene = \"mid_gate\"\n",
    "\n",
    "courses = [\"traverse\"]   \n",
    "\n",
    "roster = [\"clanGhostBear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Rollouts\n",
    "rg.generate_rollout_data(cohort,[\"traverse\"],\"mid_gate\",\"eval_single\")\n",
    "rg.generate_rollout_data(cohort,[\"circuit\"],\"backroom\",\"eval_single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "Tro,Xro,Uro,Iro = fu.extract_rollout_data(cohort,\"traverse\")\n",
    "data[\"traverse\"] = {\"Tro\":Tro,\"Xro\":Xro,\"Uro\":Uro,\"Iro\":Iro}\n",
    "\n",
    "Tro,Xro,Uro,Iro = fu.extract_rollout_data(cohort,\"circuit\")\n",
    "data[\"circuit\"] = {\"Tro\":Tro,\"Xro\":Xro,\"Uro\":Uro,\"Iro\":Iro}\n",
    "\n",
    "# image = Image.open('elephant1.jpeg').convert('RGB')  # ensure RGB\n",
    "# image_np = np.expand_dims(np.array(image),axis=0)  # shape: (H, W, 3), dtype=uint8\n",
    "# data[\"elephant\"] = {\"Tro\":None,\"Xro\":None,\"Uro\":None,\"Iro\":image_np}\n",
    "\n",
    "# images = []\n",
    "# for i in range(1,6):\n",
    "#     image = Image.open(f'ladder{i}.jpg').convert('RGB')  # ensure RGB\n",
    "#     image_np =np.array(image)\n",
    "#     images.append(image_np)\n",
    "# data[\"ladder\"] = {\"Tro\":None,\"Xro\":None,\"Uro\":None,\"Iro\":images}\n",
    "\n",
    "# images = []\n",
    "# for i in range(1,5):\n",
    "#     image = Image.open(f'test{i}.png').convert('RGB')  # ensure RGB\n",
    "#     image_np =np.array(image)\n",
    "#     images.append(image_np)\n",
    "# data[\"test\"] = {\"Tro\":None,\"Xro\":None,\"Uro\":None,\"Iro\":images}\n",
    "\n",
    "# images = []\n",
    "# for i in range(1,4):\n",
    "#     image = Image.open(f'cabinet{i}.jpg').convert('RGB')  # ensure RGB\n",
    "#     image_np =np.array(image)\n",
    "#     images.append(image_np)\n",
    "# data[\"cabinet\"] = {\"Tro\":None,\"Xro\":None,\"Uro\":None,\"Iro\":images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables\n",
    "vit_rg = fe.VitB16()\n",
    "vit_dn = fe.DINOv2()\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = data[\"traverse\"][\"Iro\"]\n",
    "imgs = data[\"circuit\"][\"Iro\"]\n",
    "# imgs = data[\"elephant\"][\"Iro\"]\n",
    "# imgs = data[\"test\"][\"Iro\"]\n",
    "# imgs = data[\"ladder\"][\"Iro\"]\n",
    "\n",
    "# Extract initial patch\n",
    "N = len(imgs)\n",
    "Ynn_rg,Ynn_dn = [], []\n",
    "Cls_rg,Cls_dn = [], []\n",
    "for img in imgs:\n",
    "    with torch.no_grad():\n",
    "        img_in = fu.process_image(img).unsqueeze(0)\n",
    "\n",
    "        ynn_rg,cls_rg = vit_rg(img_in)\n",
    "        ynn_dn,cls_dn = vit_dn(img_in)\n",
    "        Ynn_rg.append(ynn_rg)\n",
    "        Ynn_dn.append(ynn_dn)\n",
    "        Cls_rg.append(cls_rg)\n",
    "        Cls_dn.append(cls_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Image\n",
    "img_idx = 3\n",
    "\n",
    "pca_img_rg = pca.fit_transform(Ynn_rg[img_idx])\n",
    "pca_img_dn = pca.fit_transform(Ynn_dn[img_idx])\n",
    "\n",
    "pca_img_rg = pca_img_rg.reshape(14,14,3)\n",
    "pca_img_dn = pca_img_dn.reshape(16,16,3)\n",
    "\n",
    "for i in range(3):\n",
    "    overlay1 = fu.heatmap_overlay(pca_img_rg[:,:,i],imgs[img_idx])\n",
    "    overlay2 = fu.heatmap_overlay(pca_img_dn[:,:,i],imgs[img_idx])\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    axs[0].imshow(overlay1)\n",
    "    axs[1].imshow(overlay2)\n",
    "\n",
    "overlay1 = fu.pca_overlay(pca_img_rg)\n",
    "overlay2 = fu.pca_overlay(pca_img_dn)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs[0].imshow(overlay1)\n",
    "axs[1].imshow(overlay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Images\n",
    "Ynn_rg_out = torch.cat(Ynn_rg,dim=0)\n",
    "Ynn_dn_out = torch.cat(Ynn_dn,dim=0)\n",
    "\n",
    "pca_img_rg = pca.fit_transform(Ynn_rg_out)\n",
    "pca_img_dn = pca.fit_transform(Ynn_dn_out)\n",
    "\n",
    "pca_img_rg = pca_img_rg.reshape(len(imgs),14,14,3)\n",
    "pca_img_dn = pca_img_dn.reshape(len(imgs),16,16,3)\n",
    "\n",
    "for i in range(3):\n",
    "    overlay1 = fu.heatmap_overlay(pca_img_rg[-1,:,:,i],img)\n",
    "    overlay2 = fu.heatmap_overlay(pca_img_dn[-1,:,:,i],img)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    axs[0].imshow(overlay1)\n",
    "    axs[1].imshow(overlay2)\n",
    "\n",
    "overlay1 = fu.pca_overlay(pca_img_rg[-1,:,:,:])\n",
    "overlay2 = fu.pca_overlay(pca_img_dn[-1,:,:,:])\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs[0].imshow(overlay1)\n",
    "axs[1].imshow(overlay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live Video\n",
    "Ynn_rg_out = Ynn_rg\n",
    "Ynn_dn_out = Ynn_dn\n",
    "\n",
    "n = 20\n",
    "threshold = 0.6\n",
    "\n",
    "Hmap_rg = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "Hmap_dn = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "muHmap_rg_out = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "muHmap_dn_out = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "for i in range(n,N):\n",
    "    Ynns_rg = Ynn_rg_out[i-n:i]\n",
    "    Ynns_dn = Ynn_dn_out[i-n:i]\n",
    "    Ynns_rg = torch.cat(Ynns_rg,dim=0)\n",
    "    Ynns_dn = torch.cat(Ynns_dn,dim=0)\n",
    "\n",
    "    pca_img_rg = pca.fit_transform(Ynns_rg)\n",
    "    pca_img_dn = pca.fit_transform(Ynns_dn)\n",
    "\n",
    "    pca_img_rg = pca_img_rg.reshape(n,14,14,3)\n",
    "    pca_img_dn = pca_img_dn.reshape(n,16,16,3)\n",
    "\n",
    "    mu_pca_img_rg = np.mean(pca_img_rg,axis=3)\n",
    "    mu_pca_img_dn = np.mean(pca_img_dn,axis=3)\n",
    "\n",
    "    Hmap_rg[i,:,:,:] = fu.heatmap_overlay(pca_img_rg[-1,:,:,0],imgs[i],threshold=threshold)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(pca_img_dn[-1,:,:,0],imgs[i],threshold=threshold)\n",
    "    muHmap_rg_out[i,:,:,:] = fu.heatmap_overlay(mu_pca_img_rg[-1,:,:],imgs[i],threshold=threshold)\n",
    "    muHmap_dn_out[i,:,:,:] = fu.heatmap_overlay(mu_pca_img_dn[-1,:,:],imgs[i],threshold=threshold)\n",
    "\n",
    "    if i == n:\n",
    "        for j in range(3):\n",
    "            overlay1 = fu.heatmap_overlay(pca_img_rg[-1,:,:,j],imgs[i],threshold=threshold)\n",
    "            overlay2 = fu.heatmap_overlay(pca_img_dn[-1,:,:,j],imgs[i],threshold=threshold)\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "            axs[0].imshow(overlay1)\n",
    "            axs[1].imshow(overlay2)\n",
    "gv.images_to_mp4(Hmap_rg, \"hmap_rg.mp4\", fps=20)\n",
    "gv.images_to_mp4(Hmap_dn, \"hmap_dn.mp4\", fps=20)\n",
    "gv.images_to_mp4(muHmap_rg_out, \"mu_hmap_rg.mp4\", fps=20)\n",
    "gv.images_to_mp4(muHmap_dn_out, \"mu_hmap_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live Single Frame\n",
    "Ynn_rg_out = Ynn_rg\n",
    "Ynn_dn_out = Ynn_dn\n",
    "\n",
    "threshold = 0.6\n",
    "fig, axs = plt.subplots(3, 2, figsize=(8, 9))\n",
    "for i in range(1):\n",
    "    ynn_rg = Ynn_rg_out[i]\n",
    "    ynn_dn = Ynn_dn_out[i]\n",
    "\n",
    "    pca_img_rg = pca.fit_transform(ynn_rg)\n",
    "    pca_img_dn = pca.fit_transform(ynn_dn)\n",
    "\n",
    "    pca_img_rg = pca_img_rg.reshape(n,14,14,3)\n",
    "    pca_img_dn = pca_img_dn.reshape(n,16,16,3)\n",
    "\n",
    "    for j in range(3):\n",
    "        overlay1 = fu.heatmap_overlay(pca_img_rg[-1,:,:,j],imgs[i],threshold=threshold)\n",
    "        overlay2 = fu.heatmap_overlay(pca_img_dn[-1,:,:,j],imgs[i],threshold=threshold)\n",
    "        \n",
    "        axs[j,0].imshow(overlay1)\n",
    "        axs[j,1].imshow(overlay2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS dot product\n",
    "idx_cls = 200\n",
    "Ynn_rg_out,Cls_rg_out = Ynn_rg,Cls_rg\n",
    "Ynn_dn_out,Cls_dn_out = Ynn_dn,Cls_dn\n",
    "\n",
    "Hmap_rg = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "Hmap_dn = np.zeros((N,img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_rg = Ynn_rg_out[i]\n",
    "    ynn_dn = Ynn_dn_out[i]\n",
    "    cls_rg = Cls_rg_out[i]\n",
    "    cls_dn = Cls_dn_out[i]\n",
    "\n",
    "    rel_rg = torch.matmul(ynn_rg,cls_rg).reshape(14,14)\n",
    "    rel_dn = torch.matmul(ynn_dn,cls_dn).reshape(16,16)\n",
    "\n",
    "    Hmap_rg[i,:,:,:] = fu.heatmap_overlay(rel_rg,imgs[i],threshold=0.8)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(rel_dn,imgs[i],threshold=0.8)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs[0].imshow(Hmap_rg[idx_cls,:,:,:])\n",
    "axs[1].imshow(Hmap_dn[idx_cls,:,:,:])\n",
    "    \n",
    "gv.images_to_mp4(Hmap_rg, \"cls_hmap_rg.mp4\", fps=20)\n",
    "gv.images_to_mp4(Hmap_dn, \"cls_hmap_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_rf = data[\"ladder\"][\"Iro\"]\n",
    "imgs_rf = data[\"cabinet\"][\"Iro\"]\n",
    "\n",
    "Nrf = len(imgs_rf)\n",
    "Yrf_rg,Yrf_dn = [], []\n",
    "Crf_rg,Crf_dn = [], []\n",
    "for img in imgs_rf:\n",
    "    with torch.no_grad():\n",
    "        img_in = fu.process_image(img).unsqueeze(0)\n",
    "\n",
    "        yrf_rg,crf_rg = vit_rg(img_in)\n",
    "        yrf_dn,crf_dn = vit_dn(img_in)\n",
    "        Yrf_rg.append(yrf_rg)\n",
    "        Yrf_dn.append(yrf_dn)\n",
    "        Crf_rg.append(crf_rg)\n",
    "        Crf_dn.append(crf_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Target on Live I\n",
    "threshold = 0.8\n",
    "targ_rg = torch.mean(torch.stack(Crf_rg),dim=0)\n",
    "targ_dn = torch.mean(torch.stack(Crf_dn),dim=0)\n",
    "\n",
    "Hmap_rg = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "Hmap_dn = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_rg = Ynn_rg[i]\n",
    "    ynn_dn = Ynn_dn[i]\n",
    "\n",
    "    rel_rg = torch.matmul(ynn_rg,targ_rg).reshape(14,14)\n",
    "    rel_dn = torch.matmul(ynn_dn,targ_dn).reshape(16,16)\n",
    "\n",
    "    Hmap_rg[i,:,:,:] = fu.heatmap_overlay(rel_rg,imgs[i],threshold=threshold)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(rel_dn,imgs[i],threshold=threshold)\n",
    "\n",
    "gv.images_to_mp4(Hmap_rg, \"targ_rg.mp4\", fps=20)\n",
    "gv.images_to_mp4(Hmap_dn, \"targ_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Target on Live II\n",
    "threshold = 0.7\n",
    "alpha = 0.3\n",
    "\n",
    "# Initialize target\n",
    "targ_dn0 = torch.mean(torch.stack(Crf_dn),dim=0)\n",
    "targ_dn = 1*targ_dn0\n",
    "\n",
    "counter = 0\n",
    "Hmap_dn = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_dn = Ynn_dn[i]\n",
    "\n",
    "    # Compute similiarities\n",
    "    rel_dn = torch.matmul(ynn_dn,targ_dn)\n",
    "    rel_dn = (rel_dn - torch.min(rel_dn)) / (torch.max(rel_dn) - torch.min(rel_dn))\n",
    "\n",
    "    # Update target\n",
    "    indices = (rel_dn > threshold).nonzero(as_tuple=True)[0]\n",
    "    if len(indices) > 40:\n",
    "        counter += 1\n",
    "        zupd = torch.mean(ynn_dn[indices,:],dim=0)\n",
    "        targ_dn = (1-alpha)*targ_dn0 + alpha*zupd\n",
    "\n",
    "    # Generate heatmap\n",
    "    rel_dn = rel_dn.reshape(16,16)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(rel_dn,imgs[i],threshold=threshold)\n",
    "print(counter)\n",
    "gv.images_to_mp4(Hmap_dn, \"targ_ema_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Target on Live III\n",
    "threshold = 0.90\n",
    "alpha = 0.2\n",
    "\n",
    "# Initialize target\n",
    "targ_dn0 = Crf_dn[2]\n",
    "targ_dn = 1*targ_dn0\n",
    "\n",
    "Hmap_dn = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_dn = Ynn_dn[i]\n",
    "\n",
    "    # Compute similiarities\n",
    "    rel_dn = torch.matmul(ynn_dn,targ_dn)\n",
    "    rel_dn = (rel_dn - torch.min(rel_dn)) / (torch.max(rel_dn) - torch.min(rel_dn))\n",
    "\n",
    "    # Generate heatmap\n",
    "    rel_dn = rel_dn.reshape(16,16)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(rel_dn,imgs[i],threshold=threshold)\n",
    "\n",
    "gv.images_to_mp4(Hmap_dn, \"targ_single_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Target on Live IV\n",
    "idx_rf = 110\n",
    "threshold = 0.99\n",
    "alpha = 0.2\n",
    "\n",
    "heat_ref = torch.zeros((16,16))\n",
    "heat_ref[14, 4] = heat_ref[13, 4] = heat_ref[12, 4] = heat_ref[11, 4] = 1\n",
    "heat_ref[10, 4] = heat_ref[10, 5] = heat_ref[ 9, 5] = heat_ref[ 8, 5] = 1\n",
    "heat_ref[13, 7] = heat_ref[12, 7] = heat_ref[11, 7] = heat_ref[10, 7] = 1\n",
    "heat_ref[ 9, 6] = heat_ref[ 8, 6] = heat_ref[ 7, 6] = heat_ref[ 6, 6] = 1\n",
    "heat_ref[ 7, 5] = heat_ref[ 6, 5] = heat_ref[ 5, 5] = heat_ref[ 4, 5] = 1\n",
    "heat_ref = heat_ref.flatten()\n",
    "\n",
    "indices = (heat_ref > 0).nonzero(as_tuple=True)[0]\n",
    "targ_dn = Ynn_dn[idx_rf][indices]\n",
    "\n",
    "Hmap_dn = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_dn = Ynn_dn[i]\n",
    "\n",
    "    # Compute similiarities\n",
    "    Rel_dn = torch.matmul(targ_dn,ynn_dn.T)\n",
    "    for j in range(20):\n",
    "        Rel_dn[j,:] = (Rel_dn[j,:] - torch.min(Rel_dn[j,:])) / (torch.max(Rel_dn[j,:]) - torch.min(Rel_dn[j,:]))\n",
    "\n",
    "    # Generate heatmap\n",
    "    Rel_dn = Rel_dn.reshape(20,16,16)\n",
    "    mask = (Rel_dn > threshold).any(dim=0).to(torch.float32)  # or .float() if needed\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(mask,imgs[i],threshold=threshold)\n",
    "\n",
    "gv.images_to_mp4(Hmap_dn, \"targ_direct_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Target on Live V\n",
    "idx_rf = 110\n",
    "threshold = 0.90\n",
    "alpha = 0.2\n",
    "\n",
    "heat_ref = torch.zeros((16,16))\n",
    "heat_ref[14, 4] = heat_ref[13, 4] = heat_ref[12, 4] = heat_ref[11, 4] = 1\n",
    "heat_ref[10, 4] = heat_ref[10, 5] = heat_ref[ 9, 5] = heat_ref[ 8, 5] = 1\n",
    "heat_ref[13, 7] = heat_ref[12, 7] = heat_ref[11, 7] = heat_ref[10, 7] = 1\n",
    "heat_ref[ 9, 6] = heat_ref[ 8, 6] = heat_ref[ 7, 6] = heat_ref[ 6, 6] = 1\n",
    "heat_ref[ 7, 5] = heat_ref[ 6, 5] = heat_ref[ 5, 5] = heat_ref[ 4, 5] = 1\n",
    "\n",
    "fig,axs = plt.subplots(1, 1, figsize=(4, 4))\n",
    "overlay = fu.heatmap_overlay(heat_ref,imgs[idx_rf],threshold=threshold)\n",
    "axs.imshow(overlay)\n",
    "heat_ref = heat_ref.flatten()\n",
    "\n",
    "indices = (heat_ref > 0).nonzero(as_tuple=True)[0]\n",
    "targ_dn = Ynn_dn[idx_rf][indices]\n",
    "targ_dn = torch.mean(targ_dn,dim=0)\n",
    "Hmap_dn = np.zeros((N,imgs[0].shape[0],imgs[0].shape[1],3),dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    ynn_dn = Ynn_dn[i]\n",
    "\n",
    "    # Compute similiarities\n",
    "    rel_dn = torch.matmul(ynn_dn,targ_dn)\n",
    "    rel_dn = (rel_dn - torch.min(rel_dn)) / (torch.max(rel_dn) - torch.min(rel_dn))\n",
    "\n",
    "    # Generate heatmap\n",
    "    rel_dn = rel_dn.reshape(16,16)\n",
    "    Hmap_dn[i,:,:,:] = fu.heatmap_overlay(rel_dn,imgs[i],threshold=threshold)\n",
    "\n",
    "gv.images_to_mp4(Hmap_dn, \"targ_direct_mean_dn.mp4\", fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nro = Iro.shape[0]\n",
    "height = Iro.shape[1]\n",
    "width = Iro.shape[2]\n",
    "\n",
    "Iout = np.zeros((Nro,height,width,3),dtype=np.uint8)\n",
    "for p in range(Nro):\n",
    "    img2 = 1*Iro[p]\n",
    "\n",
    "    img_in2 = fu.process_image(img2).unsqueeze(0)        \n",
    "    with torch.no_grad():\n",
    "        ptk2 = vit(img_in2).squeeze(0).view(16,16,-1)\n",
    "\n",
    "    cos_sims = torch.zeros((Np,16,16))\n",
    "    for i in range(Np):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                patch2 = ptk2[j,k,:]\n",
    "                cos_sims[i,j,k] = F.cosine_similarity(patches[i],patch2,dim=0)\n",
    "\n",
    "    imgs2_hots = np.zeros((16,16))\n",
    "    for i in range(Np):\n",
    "        # max_idx = torch.argmax(cos_sims[i,:,:])\n",
    "        # row,col = divmod(max_idx.item(), 16)\n",
    "\n",
    "        # imgs2_hots[row,col] = 1\n",
    "        imgs2_hots = (cos_sims[i,:,:] > 0.6).float()\n",
    "\n",
    "        \n",
    "    Iout[p,:,:,:] = fu.overlay_heatmap_on_image(imgs2_hots,img2)\n",
    "\n",
    "gv.images_to_mp4(Iout,\"output4.mp4\",fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitchen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
