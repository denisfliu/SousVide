{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful settings for interactive work\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "import os\n",
    "import torch\n",
    "import albumentations as A\n",
    "import figs.visualize.generate_videos as gv\n",
    "import sousvide.control.networks.feature_extractors as fe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sousvide.control.pilot import Pilot\n",
    "\n",
    "transform = A.Compose([                                             # Image transformation pipeline\n",
    "        A.Resize(256, 256),\n",
    "        A.CenterCrop(224, 224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "        ])            \n",
    "process_image = lambda x: transform(image=x)[\"image\"]\n",
    "\n",
    "def overlay_heatmap_on_image(heatmap, image, colormap='viridis', alpha=0.5):\n",
    "    \"\"\"\n",
    "    Overlay a 16x16 heatmap on a 360x640 RGB image.\n",
    "    \n",
    "    Args:\n",
    "        heatmap: (16, 16) array, float or uint8\n",
    "        image: (360, 640, 3) RGB image (uint8)\n",
    "        colormap: name of a matplotlib colormap\n",
    "        alpha: blending factor [0 = only image, 1 = only heatmap]\n",
    "\n",
    "    Returns:\n",
    "        overlayed RGB image (uint8)\n",
    "    \"\"\"\n",
    "    # Normalize heatmap to [0, 1]\n",
    "    heatmap = heatmap.astype(np.float32)\n",
    "    heatmap -= heatmap.min()\n",
    "    heatmap /= (heatmap.max() + 1e-8)\n",
    "\n",
    "    # Resize heatmap to match image size\n",
    "    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    heatmap_colored = cmap(heatmap_resized)[:, :, :3]  # drop alpha\n",
    "    heatmap_colored = (heatmap_colored * 255).astype(np.uint8)\n",
    "\n",
    "    # Blend with original image\n",
    "    overlay = cv2.addWeighted(image, 1 - alpha, heatmap_colored, alpha, 0)\n",
    "\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"experimental_features\"\n",
    "\n",
    "data_method = \"eval_single\"\n",
    "eval_method = \"eval_single\"\n",
    "\n",
    "scene = \"mid_gate\"\n",
    "\n",
    "courses = [\"traverse\"]   \n",
    "\n",
    "roster = [\"ComStar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = os.path.join(\"../cohorts/experimental_features/rollout_data/traverse\")\n",
    "\n",
    "# Load the Rollout Data\n",
    "trajs_path = os.path.join(workspace,\"trajectories\")\n",
    "imgs_path = os.path.join(workspace,\"images\")\n",
    "\n",
    "# Extract the image and trajectory files\n",
    "trajs_files = [os.path.join(trajs_path,f) for f in os.listdir(trajs_path) if f.endswith('.pt')]\n",
    "imgs_files = [os.path.join(imgs_path,f) for f in os.listdir(imgs_path) if f.endswith('.pt')]\n",
    "\n",
    "trajs_files.sort()\n",
    "imgs_files.sort()\n",
    "\n",
    "trajs_file = trajs_files[:1]\n",
    "imgs_file = imgs_files[:1]\n",
    "\n",
    "# Load the data\n",
    "traj = torch.load(trajs_file[0])[0]\n",
    "imgs = torch.load(imgs_file[0])[0]\n",
    "\n",
    "Tro,Xro,Uro = traj[\"Tro\"],traj[\"Xro\"],traj[\"Uro\"]\n",
    "Fro,tXUd,obj = traj[\"Fro\"], traj[\"tXUd\"], traj[\"obj\"]\n",
    "\n",
    "Iro = imgs[\"images\"]\n",
    "# img = Image.open(\"cow.jpg\")\n",
    "# img_array = np.array(img, dtype=np.uint8)\n",
    "# Iro = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "height,width = Iro.shape[1], Iro.shape[2]\n",
    "Nro = Iro.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/admin/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "vit = fe.DINOv2()\n",
    "# vit = fe.VitB16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "Iout = np.zeros((Nro,height,width,3),dtype=np.uint8)\n",
    "for i in range(Nro):\n",
    "    iro = process_image(Iro[i,:,:,:]).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        patch_tokens = vit(iro).squeeze(0)\n",
    "        \n",
    "    X = patch_tokens.cpu().numpy()\n",
    "    pca = PCA(n_components=4)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    v1 = pca.components_[0]\n",
    "    if i == 0:\n",
    "        vp = v1\n",
    "    v = alpha*vp + (1-alpha)*v1\n",
    "    v = v / np.linalg.norm(v)\n",
    "    vp = v\n",
    "\n",
    "    scores = X@v\n",
    "    heatmap = scores.reshape(16,16)\n",
    "    heatmap[heatmap<0.0] = 0\n",
    "    Iout[i,:,:,:] = overlay_heatmap_on_image(heatmap, Iro[i,:,:,:])\n",
    "\n",
    "gv.images_to_mp4(Iout,\"output.mp4\",fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/admin/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "Fpc = np.zeros((Nro,768))\n",
    "for i in range(Nro):\n",
    "    iro = process_image(Iro[i,:,:,:]).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        patch_tokens = vit(iro).squeeze(0)\n",
    "    X = patch_tokens.cpu().numpy()\n",
    "    pca = PCA(n_components=4)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    first_pc = pca.components_[0]\n",
    "    Fpc[i,:] = first_pc\n",
    "v1 = np.mean(Fpc,axis=0)\n",
    "v1 = v1/np.linalg.norm(v1)\n",
    "\n",
    "Iout = np.zeros((Nro,height,width,3),dtype=np.uint8)\n",
    "for i in range(Nro):\n",
    "    iro = process_image(Iro[i,:,:,:]).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        patch_tokens = vit(iro).squeeze(0)\n",
    "    X = patch_tokens.cpu().numpy()\n",
    "\n",
    "    scores = X@v1\n",
    "    heatmap = scores.reshape(16,16)\n",
    "    heatmap[heatmap<0] = 0\n",
    "    Iout[i,:,:,:] = overlay_heatmap_on_image(heatmap, Iro[i,:,:,:])\n",
    "\n",
    "gv.images_to_mp4(Iout,\"output.mp4\",fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitchen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
