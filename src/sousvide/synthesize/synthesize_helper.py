"""
Helper functions for data synthesis.
"""

import numpy as np
from scipy.spatial.transform import Rotation as R
import copy
import figs.utilities.trajectory_helper as th
import figs.dynamics.quadcopter_specifications as qs

# Fixed parameters for camera projection
Rgl2cv = np.array([                 # Rotation from OpenGL to OpenCV
    [ 1.0, 0.0, 0.0],
    [ 0.0,-1.0, 0.0],
    [ 0.0, 0.0,-1.0]
])

def generate_frames(Tsps:np.ndarray,
                    base_frame_config:dict[str,int|float|list[float]],
                    parameters_bounds:list[float],
                    rng_seed:int|None=None) -> list[dict[str,np.ndarray|str|int,float]]:
    
    """
    Generates a list of drone variations for a given base drone configuration. The configurations are
    generated by perturbing the base drone configuration with bounded uniform noise. The number of
    configurations generated is determined by the sample set config dictionary.

    Args:
        Tsps:               Sample times.
        base_frame_config:  Base frame configuration dictionary.
        parameters_bounds:  Frame sample set config dictionary.
        rng_seed:           Random number generator seed.

    Returns:
        Drones:             List of drone configurations (dictionary format).
    """

    # TODO: Generalize this to nnio config
    parameters_key = ["mass","motor_thrust_coeff"]

    # Sample Count
    Nsps = len(Tsps)

    # Set random number generator seed
    if rng_seed is not None:
        np.random.seed(rng_seed)

    # Generate Drone Frames
    Frames = []
    for _ in range(Nsps):
        # Instantiate a new frame
        frame = copy.deepcopy(base_frame_config)

        # Randomize the frame
        for idx,key in enumerate(parameters_key):
            bounds = [-parameters_bounds[idx],parameters_bounds[idx]]
            frame[key] += np.random.uniform(*bounds)

        # Save to a dictionary
        Frames.append(frame)

    return Frames

def generate_perturbations(Tsps:np.ndarray,
                           tXUd:np.ndarray,
                           initial_bounds:list[float],
                           rng_seed:int=None) -> list[dict[str,float|np.ndarray]]:
    """
    Generates a list of perturbed initial states for the drone given an ideal trajectory. The perturbed
    initial states are generated by sampling a random initial times and corresponding state vectors from
    the ideal trajectory using a bounded uniform distribution. The state vectors are then perturbed with
    uniform noise. The number of perturbed initial states generated is determined by the sample set
    config dictionary.

    Args:
        Tsps:                   Sample times.
        tXUd:                   Ideal trajectory.
        initial_bounds:         Initial state bounds.
        rng_seed:               Random number generator seed.

    Returns:
        Perturbations:          List of perturbations (dictionary format).
    """

    # Sample Count
    Nsps = len(Tsps)

    # Set random number generator seed
    if rng_seed is not None:
        np.random.seed(rng_seed)
    
    # Unpack the config
    w_x0 = np.array(initial_bounds,dtype=float)

    # Generate perturbed starting points    
    Perturbations = []
    for i in range(Nsps):
        # Sample random start time and get corresponding state vector sample
        t0 = Tsps[i]
        idx = np.where(tXUd[0,:] <= t0)[0][-1]
        x0s = tXUd[1:11,idx]
        
        # Perturb state vector sample
        w0 = np.random.uniform(-w_x0,w_x0)
        x0 = x0s + w0
        
        # Ensure quaternion is well-behaved (magnitude and closest to previous)
        idxr = np.where(tXUd[0,:] <= t0)[0][-1]
        x0[6:10] = th.obedient_quaternion(x0[6:10],tXUd[7:11,idxr])

        # Store perturbation in list
        perturbation = {"t0":t0,"x0":x0}
        Perturbations.append(perturbation)
    
    return Perturbations

def compute_Tsp_batches(t0:float,tf:float,dt_ro:float,
                        rate:int,reps:int,Nro_ds:int=None,
                        shuffle:bool=True) -> list[np.ndarray]:
    """
    Compute the sample start times for a given rollout.

    Args:
        t0:     Start time of the trajectory.
        tf:     End time of the trajectory.
        dt_ro:  Sample time for each rollout.
        rate:   Number of time points per second.
        reps:   Number of rollouts per time point.
        Nro_ds: Number of rollouts per dataset.

    Returns:
        Tsp_bts:    Array containing batches of sampled start times.

    """
    
    # Compute the trajectory duration
    dt_tt = tf - t0                                            # Total trajectory duration
    
    # Compute sample start times and batchify
    Ntp = int(rate*dt_tt)                                       # Number of time points per trajectory
    Nsp = int(reps*Ntp)                                         # Number of sample points (total)

    # Compute the sample points array
    if dt_ro == dt_tt:
        Tsp = np.array([t0]*Nsp)                                # Entire sample points array
    else:
        Tsp = np.tile(np.linspace(t0,tf,Ntp+1)[:-1],reps)     # Entire sample points array
        Tsp += np.random.uniform(-1/rate,1/rate,Nsp)        # Add some noise to the sample points array
        Tsp = np.clip(Tsp,t0,tf)                                # Clip the sample points array

    # Shuffle if required
    if shuffle:
        np.random.shuffle(Tsp)

    # Split into batches of datasets
    if Nro_ds is not None:
        Tsp_bts = np.split(Tsp,np.arange(Nro_ds,Nsp,Nro_ds))        # Split the sample points array into their batches
    else:
        Tsp_bts = [Tsp]                                             # No batching, return the entire array as a single batch
    
    return Tsp_bts

def generate_edge_projections(Tro:np.ndarray,Xro:np.ndarray,tXUd:np.ndarray,
                              frame:dict[str,list[float]|float],
                              Nhn:int=60,Nbff:int=0,p_off:float=0.1) -> np.ndarray:
    """
    Projects a path in world frame to the camera frame.

    Args:
        Tro:    Drone rollout time.
        Xro:    Drone rollout states.
        tXUd:   Ideal trajectetory.
        frame:  Frame specifications including camera parameters.
        Nhn:    Number of horizon steps to consider for edge projection (default: 60).
        Nbff:   Number of frames to buffer before horizon (default: 10).
        p_off:  Lateral offset for edge projection (default: 0.1 meters).

    Returns:
        Pcm:        Projected path in camera frame (N x 3).
    """

    # Some useful constants
    pl_off = np.array([ 0.00,-p_off, 0.00])
    pr_off = np.array([ 0.00, p_off, 0.00])

    # Unpack some useful stuff
    Nuv = Tro.shape[0]
    Spec = qs.generate_specifications(frame)
    Tcr2cm,Kcm = np.linalg.inv(Spec["Tc2b"]),Spec["K"]
    width, height = Spec["camera"]["width"], Spec["camera"]["height"]

    rUV = np.zeros((Nuv,Nhn,4))
    for i in range(Nuv):
        # Current time and state
        tcr,xcr = Tro[i], Xro[:,i]

        # Extract horizon states from the ideal trajectory
        if tcr < tXUd[0,-1]:
            idx = np.where(tcr < tXUd[0,:])[0][0]  # Find the last index where tcr is less than tXUd
        else:
            idx = tXUd.shape[1] - 1
        
        idx += Nbff          
        idxs = np.clip(np.arange(idx,idx+Nhn), 0, tXUd.shape[1]-1)
        Xhn = tXUd[1:11, idxs]

        # Goal Frame to World Frame
        Phn = Xhn[0:3,:]
        Rhn = R.from_quat(Xhn[6:10,:].T)

        Pl = Phn + Rhn.apply(pl_off).T
        Pr = Phn + Rhn.apply(pr_off).T

        Pl = np.vstack((Pl, np.ones((1, Pl.shape[1]))))
        Pr = np.vstack((Pr, np.ones((1, Pr.shape[1]))))

        # World Frame to Current Frame
        Twd2cr = np.eye(4)
        Twd2cr[0:3,0:3] = R.from_quat(xcr[6:10]).as_matrix().T
        Twd2cr[0:3,3] = -Twd2cr[0:3,0:3]@xcr[0:3]

        # Positions in camera frame
        Plcm = (Tcr2cm@Twd2cr@Pl)[0:3,:]
        Prcm = (Tcr2cm@Twd2cr@Pr)[0:3,:]

        # Project to Image Plane (in OpenCV coordinates)
        Plpr = Kcm@Rgl2cv@Plcm
        Prpr = Kcm@Rgl2cv@Prcm

        # Normalize by z
        UVl = Plpr[0:2,:] / Plpr[2,:]
        UVr = Prpr[0:2,:] / Prpr[2,:]

        # Ratio and center to image size
        rUV[i,:,0] = 2*UVl[0,:]/(width-1) - 1 
        rUV[i,:,1] = 2*UVl[1,:]/(height-1) - 1
        rUV[i,:,2] = 2*UVr[0,:]/(width-1) - 1
        rUV[i,:,3] = 2*UVr[1,:]/(height-1) - 1
        
    return rUV

def get_patch_index(u,v, patch_height, patch_width, n_rows, n_cols):

    row = int(v / patch_height)
    col = int(u / patch_width)

    # Clamp to valid index range
    row = min(max(row, 0), n_rows - 1)
    col = min(max(col, 0), n_cols - 1)

    return row, col

def get_patch_bounds(u,v, H, W, n_rows, n_cols):
    patch_height = H / n_rows
    patch_width = W / n_cols

    row,col = get_patch_index(u,v, patch_height, patch_width, n_rows, n_cols)

    top = int(round(row * patch_height))
    bottom = int(round((row + 1) * patch_height))
    left = int(round(col * patch_width))
    right = int(round((col + 1) * patch_width))

    return [top, bottom, left, right]